{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1032238,"sourceType":"datasetVersion","datasetId":568973}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, torch, librosa, sklearn, librosa.display, glob\nimport numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom IPython.display import Audio\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\nrandom_state = np.random.RandomState(0)\n\ndata_path = '/kaggle/input/gtzan-dataset-music-genre-classification/Data'\ngenres=(list(os.listdir(f'{data_path}/genres_original/')))\n\n# Alphabetize the list of genres\nsorted_genres = sorted(genres)\n\n# Create a dictionary with genres as keys and values from 0 to n-1\ngenre_dict = {genre: index for index, genre in enumerate(sorted_genres)}\nprint(genre_dict)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-12T01:27:55.606823Z","iopub.execute_input":"2023-12-12T01:27:55.607328Z","iopub.status.idle":"2023-12-12T01:27:55.629380Z","shell.execute_reply.started":"2023-12-12T01:27:55.607287Z","shell.execute_reply":"2023-12-12T01:27:55.628125Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n","output_type":"stream"}]},{"cell_type":"code","source":"# clear outputs in kaggle\ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\nfolder_path = '/kaggle/working'\nremove_folder_contents(folder_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T01:27:58.316859Z","iopub.execute_input":"2023-12-12T01:27:58.317674Z","iopub.status.idle":"2023-12-12T01:27:58.406783Z","shell.execute_reply.started":"2023-12-12T01:27:58.317630Z","shell.execute_reply":"2023-12-12T01:27:58.405436Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Transforming audio files into Mel spectrograms and saving\n\nprint(\"Transforming the Audio Files into Mel Spectrograms:\")\nbatch_size = 32\n\nhop_length = 512\nforbidden = '/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/jazz/jazz.00054.wav'\nmel_spectogram_data = {}\nfor genre in genre_dict.keys():\n    \n    mel_spectogram_data[genre] = []\n    for name in glob.glob(data_path + \"/genres_original/\" + genre + \"/*\"):\n        if name != forbidden:\n            data,sampling_rate = librosa.load(name)\n\n            mel_spec = librosa.feature.melspectrogram(y = data.ravel(), sr=sampling_rate,hop_length = hop_length)\n            mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n\n            mel_spectogram_data[genre].append(mel_spec_db)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T01:56:55.518539Z","iopub.execute_input":"2023-12-12T01:56:55.519075Z","iopub.status.idle":"2023-12-12T01:58:55.059798Z","shell.execute_reply.started":"2023-12-12T01:56:55.519036Z","shell.execute_reply":"2023-12-12T01:58:55.057935Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Transforming the Audio Files into Mel Spectrograms:\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Saving the Mel Spectrogram Images:\")\nplt.ioff()           \nx = []\ny = []\nfor genre in genre_dict.keys():\n\n   \n    for i in range(len(mel_spectogram_data[genre])):\n        plt.figure(figsize=(16, 6))\n\n        img = librosa.display.specshow(mel_spectogram_data[genre][i], sr = sampling_rate, hop_length = hop_length,cmap = 'cool', y_axis='mel', fmax=8000, x_axis='time')\n        image_path = genre + \"_\" + str(i) + \".png\"\n        x.append(image_path)\n        y.append(genre)\n        if not os.path.exists(image_path):\n            plt.savefig(image_path)\n        plt.close()\ndf = pd.DataFrame({'image_path': x, 'genre': y})","metadata":{"execution":{"iopub.status.busy":"2023-12-12T01:01:06.859308Z","iopub.execute_input":"2023-12-12T01:01:06.866094Z","iopub.status.idle":"2023-12-12T01:08:33.838394Z","shell.execute_reply.started":"2023-12-12T01:01:06.866000Z","shell.execute_reply":"2023-12-12T01:08:33.837156Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Saving the Mel Spectrogram Images:\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Split the data\nx_train, x_test, y_train, y_test = train_test_split(df['image_path'], df['genre'], stratify=df['genre'], test_size=0.3, random_state=0)\n\n# Create a new DataFrame for training data\ntrain_df = pd.DataFrame({'image_path': x_train, 'genre': y_train})\n\n# Create ImageDataGenerators\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create the training set\ntraining_set = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='image_path',\n    y_col='genre',\n    target_size=(224, 224),  # Adjusted size\n    batch_size=32,\n    class_mode='categorical',\n    subset='training',\n)\n\ntest_set = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='image_path',\n    y_col='genre',\n    target_size=(224, 224),  # Adjusted size\n    batch_size=32,\n    class_mode='categorical',\n    subset='training',\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T01:08:33.839635Z","iopub.execute_input":"2023-12-12T01:08:33.840510Z","iopub.status.idle":"2023-12-12T01:08:33.900553Z","shell.execute_reply.started":"2023-12-12T01:08:33.840470Z","shell.execute_reply":"2023-12-12T01:08:33.899652Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 560 validated image filenames belonging to 10 classes.\nFound 560 validated image filenames belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout\nfrom keras.layers import Flatten, Dense\ninput_shape=(224, 224, 3)\n\n# build network topology\n\nmodel=Sequential([\n    Flatten(input_shape=input_shape),\n    Dropout(0.2),\n    Dense(512,activation='relu'),\n    Dropout(0.2),\n    \n    Dense(256,activation='relu'),\n    Dropout(0.2),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.2),\n\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n\n    Dense(32, activation='relu'),\n    Dropout(0.2),\n\n    Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n             loss=\"sparse_categorical_crossentropy\",\n              metrics=[\"accuracy\"])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:04:37.939719Z","iopub.execute_input":"2023-12-12T02:04:37.940363Z","iopub.status.idle":"2023-12-12T02:04:38.745659Z","shell.execute_reply.started":"2023-12-12T02:04:37.940312Z","shell.execute_reply":"2023-12-12T02:04:38.744355Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(training_set,steps_per_epoch=len(training_set), validation_data=test_set, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T01:08:35.336361Z","iopub.execute_input":"2023-12-12T01:08:35.336731Z","iopub.status.idle":"2023-12-12T01:16:07.124351Z","shell.execute_reply.started":"2023-12-12T01:08:35.336691Z","shell.execute_reply":"2023-12-12T01:16:07.122607Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/10\n18/18 [==============================] - 43s 2s/step - loss: 45.2101 - accuracy: 0.1089 - val_loss: 3.5771 - val_accuracy: 0.0964\nEpoch 2/10\n18/18 [==============================] - 40s 2s/step - loss: 13.8987 - accuracy: 0.0946 - val_loss: 2.3094 - val_accuracy: 0.0946\nEpoch 3/10\n18/18 [==============================] - 40s 2s/step - loss: 6.1854 - accuracy: 0.1304 - val_loss: 2.3023 - val_accuracy: 0.1036\nEpoch 4/10\n18/18 [==============================] - 40s 2s/step - loss: 3.5140 - accuracy: 0.1018 - val_loss: 2.3023 - val_accuracy: 0.1036\nEpoch 5/10\n18/18 [==============================] - 40s 2s/step - loss: 2.7400 - accuracy: 0.1018 - val_loss: 2.3041 - val_accuracy: 0.1036\nEpoch 6/10\n18/18 [==============================] - 40s 2s/step - loss: 2.6943 - accuracy: 0.0929 - val_loss: 2.3027 - val_accuracy: 0.1036\nEpoch 7/10\n18/18 [==============================] - 40s 2s/step - loss: 2.4223 - accuracy: 0.1036 - val_loss: 2.3176 - val_accuracy: 0.1036\nEpoch 8/10\n18/18 [==============================] - 40s 2s/step - loss: 2.3737 - accuracy: 0.0875 - val_loss: 2.3027 - val_accuracy: 0.1036\nEpoch 9/10\n18/18 [==============================] - 40s 2s/step - loss: 2.3030 - accuracy: 0.1054 - val_loss: 2.3026 - val_accuracy: 0.1036\nEpoch 10/10\n18/18 [==============================] - 40s 2s/step - loss: 2.3027 - accuracy: 0.1036 - val_loss: 2.3026 - val_accuracy: 0.1036\n","output_type":"stream"}]},{"cell_type":"code","source":"# Display results. Doesn't work yet\n\nacc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, '-', label='Training Accuracy')\nplt.plot(epochs, val_acc, ':', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.plot()","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:16:50.618616Z","iopub.execute_input":"2023-12-12T02:16:50.619111Z","iopub.status.idle":"2023-12-12T02:16:50.639178Z","shell.execute_reply.started":"2023-12-12T02:16:50.619075Z","shell.execute_reply":"2023-12-12T02:16:50.638342Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]}]}